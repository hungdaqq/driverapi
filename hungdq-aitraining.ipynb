{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/mobilevit/models/models')","metadata":{"execution":{"iopub.status.busy":"2023-11-02T14:57:56.734413Z","iopub.execute_input":"2023-11-02T14:57:56.734793Z","iopub.status.idle":"2023-11-02T14:57:56.745767Z","shell.execute_reply.started":"2023-11-02T14:57:56.734763Z","shell.execute_reply":"2023-11-02T14:57:56.744842Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from mobilevitv1 import MobileViT\nfrom mobilevitv2 import MobileViTv2","metadata":{"execution":{"iopub.status.busy":"2023-11-02T14:57:56.747651Z","iopub.execute_input":"2023-11-02T14:57:56.747944Z","iopub.status.idle":"2023-11-02T14:57:58.204559Z","shell.execute_reply.started":"2023-11-02T14:57:56.747921Z","shell.execute_reply":"2023-11-02T14:57:58.203460Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms, models\nfrom torchvision.datasets import ImageFolder\n\nimage_size = (256,256)\nnum_classes = 10\nbatch_size = 64\nnum_epochs = 50\nlr = 1e-3\nseed = 42\ntorch.manual_seed(seed)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False","metadata":{"execution":{"iopub.status.busy":"2023-11-02T14:57:58.205792Z","iopub.execute_input":"2023-11-02T14:57:58.206173Z","iopub.status.idle":"2023-11-02T14:57:58.714305Z","shell.execute_reply.started":"2023-11-02T14:57:58.206146Z","shell.execute_reply":"2023-11-02T14:57:58.713172Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Additional augmentations\ntrain_transform = transforms.Compose([\n    transforms.Resize(image_size),\n    transforms.RandomRotation(degrees=10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n    transforms.RandomAffine(degrees=0, translate=(0.2, 0.2)),\n    transforms.RandomGrayscale(p=0.1),\n    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\nval_transform = transforms.Compose([\n    transforms.Resize(image_size),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])","metadata":{"execution":{"iopub.status.busy":"2023-11-02T14:57:58.715890Z","iopub.execute_input":"2023-11-02T14:57:58.716254Z","iopub.status.idle":"2023-11-02T14:57:58.726613Z","shell.execute_reply.started":"2023-11-02T14:57:58.716221Z","shell.execute_reply":"2023-11-02T14:57:58.725444Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Define the path to your dataset\n# train_path ='/kaggle/input/statefarm/train/'\n# test_path ='/kaggle/input/statefarm/test/'\n# train_path ='/kaggle/input/auc-v2/v2/v2/cam1/train/'\n# test_path ='/kaggle/input/auc-v2/v2/v2/cam1/test/'\ntrain_path ='/kaggle/input/auc-v2/v1/v1/train/'\ntest_path ='/kaggle/input/auc-v2/v1/v1/test/'\n\n# Create the ImageFolder dataset\ntrain_dataset = ImageFolder(root=train_path, transform=train_transform)\ntest_dataset = ImageFolder(root=test_path, transform=val_transform)\n\n# Create data loaders\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T14:57:58.729626Z","iopub.execute_input":"2023-11-02T14:57:58.729951Z","iopub.status.idle":"2023-11-02T14:58:03.262624Z","shell.execute_reply.started":"2023-11-02T14:57:58.729922Z","shell.execute_reply":"2023-11-02T14:58:03.261453Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Define your model architecture (make sure it matches the one used during training)\n\n# model = MobileViTv2(\n#     image_size = image_size, \n#     width_multiplier = 0.5,             # support [0.5, 0.75, 1, 1.25, 1.5, 1.75, 2] as shown in paper\n#     num_classes=num_classes, \n#     patch_size=(2, 2)\n# )\n\n# model = models.resnet50(pretrained=True)\n# model.fc = nn.Sequential(\n#     nn.Dropout(p=0.2, inplace=False),\n#     nn.Linear(in_features=model.fc.in_features, out_features=num_cls, bias=True)\n# )\n\nmodel = MobileViT(\n    image_size=image_size,\n    mode='small',\n    num_classes=1000,\n    patch_size=(2,2)\n)\npretrained = '/kaggle/input/mobilevit/pretrained/pretrained/mobilevit_s.pt'\nmodel.load_state_dict(torch.load(pretrained, map_location=device))\nmodel.classifier.fc = nn.Linear(in_features=model.classifier.fc.in_features, out_features=num_classes, bias=True)\n\nmodel = nn.DataParallel(model)\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T14:58:03.264123Z","iopub.execute_input":"2023-11-02T14:58:03.264514Z","iopub.status.idle":"2023-11-02T14:58:06.865975Z","shell.execute_reply.started":"2023-11-02T14:58:03.264477Z","shell.execute_reply":"2023-11-02T14:58:06.865092Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01)\nscheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T14:58:06.867225Z","iopub.execute_input":"2023-11-02T14:58:06.867550Z","iopub.status.idle":"2023-11-02T14:58:06.875013Z","shell.execute_reply.started":"2023-11-02T14:58:06.867521Z","shell.execute_reply":"2023-11-02T14:58:06.873874Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import json\n# Assuming you have a list to store your logs\ntraining_logs = []","metadata":{"execution":{"iopub.status.busy":"2023-11-02T14:58:06.876588Z","iopub.execute_input":"2023-11-02T14:58:06.876945Z","iopub.status.idle":"2023-11-02T14:58:06.887265Z","shell.execute_reply.started":"2023-11-02T14:58:06.876908Z","shell.execute_reply":"2023-11-02T14:58:06.886208Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Train the model\nfor epoch in range(num_epochs):\n    model.train()\n\n    total_loss = 0\n    total_correct = 0\n    total_samples = 0\n\n    for step, (inputs, labels) in enumerate(train_loader):\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n        _, predicted = torch.max(outputs, 1)\n        total_samples += labels.size(0)\n        total_correct += (predicted == labels).sum().item()\n        \n        print(f'Epoch {epoch+1}/{num_epochs}, Step {step+1}/{len(train_loader)}, '\n              f'Train Loss: {total_loss:.4f}, Train Acc: {total_correct}', end='\\r')\n        \n    scheduler.step()\n    train_loss = total_loss / len(train_loader)\n    train_accuracy = total_correct / total_samples\n\n    # Validation\n    model.eval()\n    total_correct = 0\n    total_samples = 0\n    val_loss = 0\n\n    with torch.no_grad():\n        for step, (inputs, labels) in enumerate(val_loader):\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n\n            _, predicted = torch.max(outputs, 1)\n            total_samples += labels.size(0)\n            total_correct += (predicted == labels).sum().item()\n\n            print(f'Epoch {epoch+1}/{num_epochs}, Step {step+1}/{len(val_loader)}, '\n              f'Val Loss: {val_loss:.4f}, Val Acc: {total_correct}', end='\\r')\n\n    val_loss /= len(val_loader)\n    val_accuracy = total_correct / total_samples\n    \n    log_entry = {\n        'epoch': epoch + 1,\n        'train_loss': train_loss,\n        'train_accuracy': train_accuracy,\n        'val_loss': val_loss,\n        'val_accuracy': val_accuracy,\n        'learning_rate': optimizer.param_groups[0][\"lr\"]\n    }\n\n    training_logs.append(log_entry)\n    \n    print(f'Epoch {epoch+1}/{num_epochs}, '\n          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, '\n          f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}',\n          f'Learning Rate: {optimizer.param_groups[0][\"lr\"]:.6f}')","metadata":{"execution":{"iopub.status.busy":"2023-11-02T14:58:06.888754Z","iopub.execute_input":"2023-11-02T14:58:06.889193Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/50, Train Loss: 1.5477, Train Accuracy: 0.4797, Val Loss: 1.3037, Val Accuracy: 0.5451 Learning Rate: 0.000900\nEpoch 2/50, Train Loss: 1.0342, Train Accuracy: 0.6675, Val Loss: 1.7492, Val Accuracy: 0.4606 Learning Rate: 0.000810\nEpoch 3/50, Train Loss: 1.0145, Train Accuracy: 0.6767, Val Loss: 1.2267, Val Accuracy: 0.5825 Learning Rate: 0.000729\nEpoch 4/50, Train Loss: 0.9739, Train Accuracy: 0.6966, Val Loss: 1.2122, Val Accuracy: 0.6047 Learning Rate: 0.000656\nEpoch 5/50, Train Loss: 0.9435, Train Accuracy: 0.6973, Val Loss: 0.8548, Val Accuracy: 0.7366 Learning Rate: 0.000590\nEpoch 6/50, Train Loss: 0.8918, Train Accuracy: 0.7173, Val Loss: 0.9142, Val Accuracy: 0.7086 Learning Rate: 0.000531\nEpoch 7/50, Step 103/203, Train Loss: 86.1243, Train Acc: 4869\r","output_type":"stream"}]},{"cell_type":"code","source":"# Save the logs to a JSON file\nwith open('training_logs.json', 'w') as json_file:\n    json.dump(training_logs, json_file)\n# Save the trained model\ntorch.save(model.state_dict(), f'mobilevit_{num_epochs}.pt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}