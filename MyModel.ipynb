{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Import libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import sys\n","import random \n","sys.path.append('/kaggle/input/mobilevit/models/models')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from mobilevitv1 import MobileViT\n","from mobilevitv2 import MobileViTv2\n","from MyModel import MyModel"]},{"cell_type":"markdown","metadata":{},"source":["# Hyperparams"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, random_split, Subset\n","from torchvision import transforms, models\n","from torchvision.datasets import ImageFolder\n","\n","image_size = (256,256)\n","num_classes = 10\n","batch_size = 64\n","num_epochs = 50\n","lr = 1e-3\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_transform = transforms.Compose([\n","    transforms.Resize(image_size),\n","    transforms.CenterCrop((240,240)),\n","    transforms.RandomRotation(degrees=10),\n","    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n","    transforms.RandomAffine(degrees=0, translate=(0.2, 0.2)),\n","    transforms.RandomGrayscale(p=0.1),\n","    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","val_transform = transforms.Compose([\n","    transforms.Resize(image_size),\n","    transforms.CenterCrop((240,240)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])"]},{"cell_type":"markdown","metadata":{},"source":["### Train 3MDAD"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","import torch\n","from torchvision import transforms, datasets\n","from torch.utils.data import DataLoader, Dataset\n","from PIL import Image\n","\n","num_classes = 16 \n","# front_directory = '/kaggle/input/3mdad-dataset/Front/Front'\n","# side_directory = '/kaggle/input/3mdad-dataset/Side/Side'\n","\n","# front_ir_directory = '/kaggle/input/convert/front_ir/front'\n","side_ir_directory = '/kaggle/input/convert-side/side_ir/side'\n","\n","# folder_names = sorted(os.listdir(root_directory), key=lambda x: int(x[1:]))\n","\n","# front_folders = sorted(os.listdir(front_directory), key=lambda x: int(x[1:]))\n","# front_ir_folders = sorted(os.listdir(front_ir_directory), key=lambda x: int(x[1:]))\n","\n","# side_folders = sorted(os.listdir(side_directory), key=lambda x: int(x[1:]))\n","side_ir_folders = sorted(os.listdir(side_ir_directory), key=lambda x: int(x[1:]))\n","\n","# train_folder_names = side_folders[0:49]\n","# test_folder_names = side_folders[40:50]\n","train_folder_names = side_ir_folders[0:15]\n","test_folder_names = side_ir_folders[15:19]\n","\n","print(\"train\" + str(train_folder_names))\n","print(\"test: \" + str(test_folder_names))\n","\n","train_dataset = [datasets.ImageFolder(root=os.path.join(side_ir_directory, folder), transform=train_transform) for folder in train_folder_names]\n","test_dataset = [datasets.ImageFolder(root=os.path.join(side_ir_directory, folder), transform=val_transform) for folder in test_folder_names]\n","\n","train_dataset = torch.utils.data.ConcatDataset(train_dataset)\n","test_dataset = torch.utils.data.ConcatDataset(test_dataset)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Train HD3D"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# import os\n","# import torch\n","# from torchvision import transforms, datasets\n","# from torch.utils.data import DataLoader\n","# batch_size = 64\n","\n","# root_directory = '/kaggle/input/howdrive3d'\n","# # Get the list of all folders\n","# folder_names = os.listdir(root_directory)\n","\n","# # Use 9 folders for training and the remaining 1 folder for testing\n","# test_folder_names = [random.choice(folder_names)]\n","# train_folder_names = [folder for folder in folder_names if folder != test_folder_names[0]]\n","# print(\"train\" + str(train_folder_names))\n","# print(\"test: \" + str(test_folder_names))\n","\n","# # Create DataLoader for training and testing sets\n","# train_dataset = [datasets.ImageFolder(root=os.path.join(root_directory, folder), transform=train_transform) for folder in train_folder_names]\n","# test_dataset = [datasets.ImageFolder(root=os.path.join(root_directory, folder), transform=val_transform) for folder in test_folder_names]\n","\n","# train_dataset = torch.utils.data.ConcatDataset(train_dataset)\n","# test_dataset = torch.utils.data.ConcatDataset(test_dataset)\n","\n","# classes = ['c' + str(i) for i in range(10)]"]},{"cell_type":"markdown","metadata":{},"source":["HD3D -> AUC"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# # train_path ='/kaggle/input/auc-v2/v1/v1/train/'\n","# test_path ='/kaggle/input/auc-v2/v1/v1/test/'\n","\n","# # train_dataset = ImageFolder(root=train_path, transform=train_transform)\n","# test_dataset = ImageFolder(root=test_path, transform=val_transform)"]},{"cell_type":"markdown","metadata":{},"source":["Cross HD3D -> StateFarm"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# import os\n","# import torch\n","# from torchvision import transforms, datasets\n","# from torch.utils.data import DataLoader\n","\n","# test_path = '/kaggle/input/statefarm/'\n","# test_dataset = ImageFolder(root=test_path, transform=val_transform)"]},{"cell_type":"markdown","metadata":{},"source":["Cross StateFarm -> HD3D "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# import os\n","# import torch\n","# from torchvision import transforms, datasets\n","# from torch.utils.data import DataLoader\n","\n","# test_dataset = train_dataset\n","# train_path = '/kaggle/input/statefarm/'\n","# train_dataset = ImageFolder(root=train_path, transform=train_transform)"]},{"cell_type":"markdown","metadata":{},"source":["Cross AUC -> HD3D"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# import os\n","# import torch\n","# from torchvision import transforms, datasets\n","# from torch.utils.data import DataLoader\n","\n","# train_path = '/kaggle/input/auc-v2/v2/v2/cam1/train'\n","# train_dataset = ImageFolder(root=train_path, transform=train_transform)"]},{"cell_type":"markdown","metadata":{},"source":["### Train StateFarm"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# statefarm_path = '/kaggle/input/statefarm/'\n","# dataset = ImageFolder(root=statefarm_path, transform=val_transform)\n","# train_size = int(0.8 * len(dataset))\n","# val_size = len(dataset) - train_size\n","# train_dataset, test_dataset = random_split(dataset, [train_size, val_size])\n","\n","# print(len(train_dataset))\n","# print(len(test_dataset))\n","\n","# classes = ['c' + str(i) for i in range(10)]"]},{"cell_type":"markdown","metadata":{},"source":["StateFarm -> AUC"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# test_path ='/kaggle/input/auc-v2/v1/v1/test/'\n","# test_dataset = ImageFolder(root=test_path, transform=val_transform)"]},{"cell_type":"markdown","metadata":{},"source":["StateFarm -> HD3D"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# import os\n","# import torch\n","# from torchvision import transforms, datasets\n","# from torch.utils.data import DataLoader\n","\n","# statefarm_path = '/kaggle/input/statefarm/'\n","# train_dataset = ImageFolder(root=statefarm_path, transform=train_transform)\n","\n","# root_directory = '/kaggle/input/howdrive3d'\n","# folder_names = os.listdir(root_directory)\n","# test_dataset = [datasets.ImageFolder(root=os.path.join(root_directory, folder), transform=val_transform) for folder in folder_names]\n","# test_dataset = torch.utils.data.ConcatDataset(test_dataset)\n","\n","# classes = ['c' + str(i) for i in range(num_classes)]\n","# print(classes)"]},{"cell_type":"markdown","metadata":{},"source":["### AUC"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# # train_path ='/kaggle/input/auc-v2/v2/v2/cam1/train/'\n","# # test_path ='/kaggle/input/auc-v2/v2/v2/cam1/val/'\n","# train_path ='/kaggle/input/auc-v2/v1/v1/train/'\n","# test_path ='/kaggle/input/auc-v2/v1/v1/test/'\n","\n","# train_dataset = ImageFolder(root=train_path, transform=train_transform)\n","# test_dataset = ImageFolder(root=test_path, transform=val_transform)\n","\n","# train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n","# val_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n","\n","# classes = ['c' + str(i) for i in range(10)]"]},{"cell_type":"markdown","metadata":{},"source":["AUC -> StateFarm"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# statefarm_path = '/kaggle/input/statefarm/'\n","# test_dataset = ImageFolder(root=statefarm_path, transform=val_transform)"]},{"cell_type":"markdown","metadata":{},"source":["### Add subset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_size = len(train_dataset)\n","test_size = len(test_dataset)\n","\n","# train_indices = list(range(train_size))\n","# test_indices = list(range(test_size))\n","\n","train_subset_size = int(0.5 * train_size)\n","test_subset_size = int(0.5 * test_size)\n","\n","train_subset, _ = random_split(train_dataset, [train_subset_size, len(train_dataset) - train_subset_size])\n","test_subset, _ = random_split(test_dataset, [test_subset_size, len(test_dataset) - test_subset_size])\n","\n","print(\"Len train subset: \" + str(len(train_subset)))\n","print(\"Len test subset: \" + str(len(test_subset)))\n","\n","train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=False)\n","\n","classes = ['c' + str(i) for i in range(num_classes)]\n","print(classes)"]},{"cell_type":"markdown","metadata":{},"source":["# Define Model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Define your model architecture (make sure it matches the one used during training)\n","\n","model = MyModel(\n","    image_size=(256,256),\n","    mode='x_small',\n","    num_classes=10,\n","    patch_size=(2,2)\n",")\n","pretrained = '/kaggle/input/mobilevit/pretrained/pretrained/mobilevit/checkpoint.pt'\n","model.load_state_dict(torch.load(pretrained, map_location=device),strict=False)\n","model.classifier.fc = nn.Linear(in_features=model.classifier.fc.in_features, out_features=num_classes, bias=True)\n","\n","# model = nn.DataParallel(model)\n","model = model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.AdamW(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01)\n","scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import json\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","# Assuming you have a list to store your logs\n","training_logs = []"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Train the model\n","best_val_accuracy = 0.0\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","\n","    total_loss = 0\n","    total_correct = 0\n","    total_samples = 0\n","\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","        _, predicted = torch.max(outputs, 1)\n","        total_samples += labels.size(0)\n","        total_correct += (predicted == labels).sum().item()\n","        \n","        print(f'Epoch {epoch+1}/{num_epochs}, Step {step+1}/{len(train_loader)}, '\n","              f'Train Loss: {total_loss:.4f}, Train Acc: {total_correct}', end='\\r')\n","        \n","    scheduler.step()\n","    train_loss = total_loss / len(train_loader)\n","    train_accuracy = total_correct / total_samples\n","\n","    # Validation\n","    model.eval()\n","    total_correct = 0\n","    total_samples = 0\n","    val_loss = 0\n","    all_predicted_labels = []\n","    all_true_labels = []\n","    \n","    with torch.no_grad():\n","        for step, (inputs, labels) in enumerate(val_loader):\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","\n","            _, predicted = torch.max(outputs, 1)\n","            total_samples += labels.size(0)\n","            total_correct += (predicted == labels).sum().item()\n","\n","            print(f'Epoch {epoch+1}/{num_epochs}, Step {step+1}/{len(val_loader)}, '\n","              f'Val Loss: {val_loss:.4f}, Val Acc: {total_correct}', end='\\r')\n","            \n","            all_predicted_labels.extend(predicted.cpu().numpy())\n","            all_true_labels.extend(labels.cpu().numpy())\n","\n","    val_loss /= len(val_loader)\n","    val_accuracy = total_correct / total_samples\n","    \n","    if val_accuracy > best_val_accuracy:\n","        best_val_accuracy = val_accuracy\n","        best_model_path = f'mymodel_{val_accuracy:.4f}.pt'\n","        torch.save(model.state_dict(), best_model_path)\n","        print(f'Saving the model with the best validation accuracy: {best_model_path}')\n","        \n","        # Calculate confusion matrix and class-wise accuracy\n","        cm = confusion_matrix(all_true_labels, all_predicted_labels)\n","        class_accuracy = cm.diagonal() / cm.sum(axis=1)\n","        cm = cm / cm.sum(axis=1, keepdims=True) * 100\n","        # Plot confusion matrix with a more beautiful style\n","        plt.figure(figsize=(16, 14))\n","        sns.set(font_scale=1.2)\n","        heatmap = sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n","        plt.title(f'Ma trận lỗi, Top-1: {val_accuracy*100:.2f}%', fontsize=16)\n","        plt.xlabel('Dự đoán',fontsize=14)\n","        plt.ylabel('Thực tế',fontsize=14)\n","        plt.show()\n","\n","    log_entry = {\n","        'epoch': epoch + 1,\n","        'train_loss': train_loss,\n","        'train_accuracy': train_accuracy,\n","        'val_loss': val_loss,\n","        'val_accuracy': val_accuracy,\n","        'learning_rate': optimizer.param_groups[0][\"lr\"]\n","    }\n","\n","    training_logs.append(log_entry)\n","    \n","    print(f'Epoch {epoch+1}/{num_epochs}, '\n","          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, '\n","          f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}',\n","          f'Learning Rate: {optimizer.param_groups[0][\"lr\"]:.6f}')\n","\n","# Save the logs to a JSON file\n","with open('training_logs.json', 'w') as json_file:\n","    json.dump(training_logs, json_file) "]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":3927802,"sourceId":6901431,"sourceType":"datasetVersion"},{"datasetId":3883556,"sourceId":7226960,"sourceType":"datasetVersion"},{"datasetId":4170885,"sourceId":7347754,"sourceType":"datasetVersion"},{"datasetId":3923663,"sourceId":7359469,"sourceType":"datasetVersion"},{"sourceId":158457510,"sourceType":"kernelVersion"},{"sourceId":158536995,"sourceType":"kernelVersion"}],"dockerImageVersionId":30558,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
