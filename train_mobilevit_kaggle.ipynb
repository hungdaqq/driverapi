{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import sys\n","sys.path.append('/kaggle/input/mobilevit/models/models')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from mobilevitv1 import MobileViT\n","from mobilevitv2 import MobileViTv2"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision import transforms, models\n","from torchvision.datasets import ImageFolder\n","\n","image_size = (256,256)\n","num_classes = 10\n","batch_size = 32\n","num_epochs = 50\n","lr = 1e-3\n","seed = 42\n","torch.manual_seed(seed)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Additional augmentations\n","train_transform = transforms.Compose([\n","    transforms.Resize(image_size),\n","    transforms.RandomRotation(degrees=10),\n","    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n","    transforms.RandomAffine(degrees=0, translate=(0.2, 0.2)),\n","    transforms.RandomGrayscale(p=0.1),\n","    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","val_transform = transforms.Compose([\n","    transforms.Resize(image_size),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Define the path to your dataset\n","# train_path ='/kaggle/input/statefarm/train/'\n","# test_path ='/kaggle/input/statefarm/test/'\n","# train_path ='/kaggle/input/auc-v2/v2/v2/cam1/train/'\n","# test_path ='/kaggle/input/auc-v2/v2/v2/cam1/test/'\n","train_path ='/kaggle/input/auc-v2/v1/v1/train/'\n","test_path ='/kaggle/input/auc-v2/v1/v1/test/'\n","\n","# Create the ImageFolder dataset\n","train_dataset = ImageFolder(root=train_path, transform=train_transform)\n","test_dataset = ImageFolder(root=test_path, transform=val_transform)\n","\n","# Create data loaders\n","train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Define your model architecture (make sure it matches the one used during training)\n","\n","# model = MobileViTv2(\n","#     image_size = image_size, \n","#     width_multiplier = 0.5,             # support [0.5, 0.75, 1, 1.25, 1.5, 1.75, 2] as shown in paper\n","#     num_classes=num_classes, \n","#     patch_size=(2, 2)\n","# )\n","\n","# model = models.resnet50(pretrained=True)\n","# model.fc = nn.Sequential(\n","#     nn.Dropout(p=0.2, inplace=False),\n","#     nn.Linear(in_features=model.fc.in_features, out_features=num_cls, bias=True)\n","# )\n","\n","model = MobileViT(\n","    image_size=image_size,\n","    mode='small',\n","    num_classes=1000,\n","    patch_size=(2,2)\n",")\n","pretrained = '/kaggle/input/mobilevit/pretrained/pretrained/mobilevit_xxs.pt'\n","model.load_state_dict(torch.load(pretrained, map_location=device))\n","model.classifier.fc = nn.Linear(in_features=model.classifier.fc.in_features, out_features=num_classes, bias=True)\n","\n","model = model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01)\n","scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import json\n","# Assuming you have a list to store your logs\n","training_logs = []"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Train the model\n","for epoch in range(num_epochs):\n","    model.train()\n","\n","    total_loss = 0\n","    total_correct = 0\n","    total_samples = 0\n","\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","        _, predicted = torch.max(outputs, 1)\n","        total_samples += labels.size(0)\n","        total_correct += (predicted == labels).sum().item()\n","        \n","        print(f'Epoch {epoch+1}/{num_epochs}, Step {step+1}/{len(train_loader)}, '\n","              f'Train Loss: {total_loss:.4f}, Train Acc: {total_correct}', end='\\r')\n","        \n","    scheduler.step()\n","    train_loss = total_loss / len(train_loader)\n","    train_accuracy = total_correct / total_samples\n","\n","    # Validation\n","    model.eval()\n","    total_correct = 0\n","    total_samples = 0\n","    val_loss = 0\n","\n","    with torch.no_grad():\n","        for step, (inputs, labels) in enumerate(val_loader):\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","\n","            _, predicted = torch.max(outputs, 1)\n","            total_samples += labels.size(0)\n","            total_correct += (predicted == labels).sum().item()\n","\n","            print(f'Epoch {epoch+1}/{num_epochs}, Step {step+1}/{len(val_loader)}, '\n","              f'Val Loss: {val_loss:.4f}, Val Acc: {total_correct}', end='\\r')\n","\n","    val_loss /= len(val_loader)\n","    val_accuracy = total_correct / total_samples\n","    \n","    log_entry = {\n","        'epoch': epoch + 1,\n","        'train_loss': train_loss,\n","        'train_accuracy': train_accuracy,\n","        'val_loss': val_loss,\n","        'val_accuracy': val_accuracy,\n","        'learning_rate': optimizer.param_groups[0][\"lr\"]\n","    }\n","\n","    training_logs.append(log_entry)\n","    \n","    print(f'Epoch {epoch+1}/{num_epochs}, '\n","          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, '\n","          f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}',\n","          f'Learning Rate: {optimizer.param_groups[0][\"lr\"]:.6f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Save the logs to a JSON file\n","with open('training_logs.json', 'w') as json_file:\n","    json.dump(training_logs, json_file)\n","# Save the trained model\n","torch.save(model.state_dict(), f'mobilevit_{num_epochs}.pt')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
