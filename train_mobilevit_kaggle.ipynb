{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/mobilevit/models/models')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mobilevitv1 import MobileViT\nfrom mobilevitv2 import MobileViTv2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_size = (256,256)\nnum_classes = 10\nbatch_size = 64\nnum_epochs = 50\nlr = 1e-3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision import transforms\n# Additional augmentations\ntransform = transforms.Compose([\n#     transforms.RandomResizedCrop(image_size, scale=(0.8, 1.0)),\n#     transforms.RandomRotation(degrees=10),\n#     transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n#     transforms.RandomAffine(degrees=0, translate=(0.2, 0.2)),\n#     transforms.RandomGrayscale(p=0.1),  # Randomly convert images to grayscale\n#     transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n    transforms.Resize(image_size),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader, random_split\n\n# Define the path to your dataset\n# train_path ='/kaggle/input/statefarm/train/'\n# test_path ='/kaggle/input/statefarm/test/'\ntrain_path ='/kaggle/input/auc-v2/v2/v2/cam1/train/'\ntest_path ='/kaggle/input/auc-v2/v2/v2/cam1/test/'\n\n# Create the ImageFolder dataset\ntrain_dataset = ImageFolder(root=train_path, transform=transform)\ntest_dataset = ImageFolder(root=test_path, transform=transform)\n\n# Create data loaders\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torchvision import models\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Define your model architecture (make sure it matches the one used during training)\n\n# model = MobileViTv2(\n#     image_size = image_size, \n#     width_multiplier = 0.5,             # support [0.5, 0.75, 1, 1.25, 1.5, 1.75, 2] as shown in paper\n#     num_classes=num_classes, \n#     patch_size=(2, 2)\n# )\n\n# model = models.resnet50(pretrained=True)\n# model.fc = nn.Sequential(\n#     nn.Dropout(p=0.2, inplace=False),\n#     nn.Linear(in_features=model.fc.in_features, out_features=num_cls, bias=True)\n# )\n\nmodel = MobileViT(\n    image_size=(256,256),\n    mode='xx_small',\n    num_classes=num_classes,\n    patch_size=(2,2)\n)\npretrained = '/kaggle/input/mobilevit/pretrained/pretrained/mobilevit_xxs.pt'\nstate_dict = torch.load(pretrained, map_location=device)\n# Update the classifier weights and biases in the state dict\nstate_dict['classifier.fc.weight'] = torch.randn(num_classes, model.classifier.fc.in_features)\nstate_dict['classifier.fc.bias'] = torch.randn(num_classes)\nmodel.load_state_dict(state_dict)\n\nmodel = model.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.optim as optim\n\n# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\nscheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\n# Assuming you have a list to store your logs\ntraining_logs = []","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\nfor epoch in range(num_epochs):\n    model.train()\n\n    total_loss = 0\n    total_correct = 0\n    total_samples = 0\n\n    for step, (inputs, labels) in enumerate(train_loader):\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n        _, predicted = torch.max(outputs, 1)\n        total_samples += labels.size(0)\n        total_correct += (predicted == labels).sum().item()\n        \n#         print(f'Epoch {epoch+1}/{num_epochs}, Step {step+1}/{len(train_loader)}, '\n#               f'Train Loss: {total_loss:.4f}, Train Acc: {total_correct}', end='\\r')\n        \n    scheduler.step()\n    train_loss = total_loss / len(train_loader)\n    train_accuracy = total_correct / total_samples\n\n    # Validation\n    model.eval()\n    total_correct = 0\n    total_samples = 0\n    val_loss = 0\n\n    with torch.no_grad():\n        for step, (inputs, labels) in enumerate(val_loader):\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n\n            _, predicted = torch.max(outputs, 1)\n            total_samples += labels.size(0)\n            total_correct += (predicted == labels).sum().item()\n\n#             print(f'Epoch {epoch+1}/{num_epochs}, Step {step+1}/{len(val_loader)}, '\n#               f'Val Loss: {val_loss:.4f}, Val Acc: {total_correct}', end='\\r')\n\n    val_loss /= len(val_loader)\n    val_accuracy = total_correct / total_samples\n    \n    log_entry = {\n        'epoch': epoch + 1,\n        'train_loss': train_loss,\n        'train_accuracy': train_accuracy,\n        'val_loss': val_loss,\n        'val_accuracy': val_accuracy,\n        'learning_rate': optimizer.param_groups[0][\"lr\"]\n    }\n\n    training_logs.append(log_entry)\n    \n    print(f'Epoch {epoch+1}/{num_epochs}, '\n          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, '\n          f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}',\n          f'Learning Rate: {optimizer.param_groups[0][\"lr\"]:.6f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the logs to a JSON file\nwith open('training_logs.json', 'w') as json_file:\n    json.dump(training_logs, json_file)\n# Save the trained model\ntorch.save(model.state_dict(), f'mobilevit_{num_epochs}.pt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}